{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibV5E-G1qMmz",
    "outputId": "5668d8c4-bae8-4b02-e722-c03dc19cc88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frngnEJrqRBE",
    "outputId": "f0735fe3-6810-4c70-8f89-f813d5f9c236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/deepsigdirect-main/uci\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/deepsigdirect-main/uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xYSpoT4qUqX"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDECHRo3qbj0"
   },
   "outputs": [],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "\n",
    "\n",
    "# evaluate random forest algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
    "# define the model\n",
    "model = RandomForestClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "\n",
    "# make predictions using random forest for classification\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
    "# define the model\n",
    "model = RandomForestClassifier()\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [[-8.52381793,5.24451077,-12.14967704,-2.92949242,0.99314133,0.67326595,-0.38657932,1.27955683,-0.60712621,3.20807316,0.60504151,-1.38706415,8.92444588,-7.43027595,-2.33653219,1.10358169,0.21547782,1.05057966,0.6975331,0.26076035]]\n",
    "yhat = model.predict(row)\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5zz82WQBWSb",
    "outputId": "07b76d9a-0bcc-4613-a7a2-9530ac2a4b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (323, 9)\n",
      "y_train : (323, 5)\n",
      "X_test : (81, 9)\n",
      "y_test : (81, 5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         0\n",
      "           1      0.941     1.000     0.970        16\n",
      "           2      0.800     0.889     0.842        18\n",
      "           3      0.941     0.696     0.800        23\n",
      "           4      0.960     1.000     0.980        24\n",
      "\n",
      "   micro avg      0.911     0.889     0.900        81\n",
      "   macro avg      0.728     0.717     0.718        81\n",
      "weighted avg      0.915     0.889     0.896        81\n",
      " samples avg      0.889     0.889     0.889        81\n",
      "\n",
      "memory 546.09375\n",
      "time 0.3330674171447754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Glass dataset\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time, psutil\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "df=pd.read_csv('glass.txt', sep=\" \", header=None)\n",
    "\n",
    "df.drop_duplicates(keep='last',inplace=True)\n",
    "\n",
    "X=df.drop(0,axis=1)\n",
    "X=normalize(X)\n",
    "y=df[0]\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros,y_ros,test_size=0.2,random_state=42)\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "print('X_train :',X_train.shape)\n",
    "print('y_train :',y_train.shape)\n",
    "print('X_test :',X_test.shape)\n",
    "print('y_test :',y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "#WHOLE PROGRAM\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory\",process.memory_info().rss/ 1024 ** 2)\n",
    "t2=time.time()\n",
    "print(\"time\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxSh3w44C8dT",
    "outputId": "990d8e1a-c1ed-46c6-955a-240327ede5e8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31488/63209982.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'X_train :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Breast dataset\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import time, psutil\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "class _Preprocess:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._label_encoder = None\n",
    "\n",
    "    def preprocess_data(self, raw_data):\n",
    "        \"\"\" Given one of UCI files specific to SigDirect paper data,\n",
    "            transform it to the common form used in sklearn datasets\"\"\"\n",
    "        transaction_data = [list(map(int, x.strip().split())) for x in raw_data]\n",
    "        max_val = max([max(x[:-1]) for x in transaction_data])\n",
    "        X, y = [], []\n",
    "\n",
    "        for transaction in transaction_data:\n",
    "            positions = np.array(transaction[:-1]) - 1\n",
    "            transaction_np = np.zeros((max_val))\n",
    "            transaction_np[positions] = 1\n",
    "            X.append(transaction_np)\n",
    "            y.append(transaction[-1])\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # converting labels\n",
    "        if self._label_encoder is None:  # train time\n",
    "            unique_classes = np.unique(y)\n",
    "            self._label_encoder = defaultdict(lambda: 0, zip(unique_classes, range(len(unique_classes))))\n",
    "            y = np.vectorize(self._label_encoder.get)(y)\n",
    "        else:  # test time\n",
    "            y = np.vectorize(lambda a: self._label_encoder[a])(y)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "prep = _Preprocess()\n",
    "with open('breast.txt') as f:\n",
    "  raw_data = f.read().strip().split('\\n')\n",
    "X, y = prep.preprocess_data(raw_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "print('X_train :',X_train.shape)\n",
    "print('y_train :',y_train.shape)\n",
    "print('X_test :',X_test.shape)\n",
    "print('y_test :',y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(accuracy_score(y_test, y_pred, digits=3))\n",
    "\n",
    "#WHOLE PROGRAM\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory\",process.memory_info().rss/ 1024 ** 2)\n",
    "t2=time.time()\n",
    "print(\"time\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qpj0IZRIDFBq",
    "outputId": "f5302c0f-f923-4785-f3b5-3acec50fea4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (592, 10)\n",
      "y_train : (592, 6)\n",
      "X_test : (148, 10)\n",
      "y_test : (148, 6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         0\n",
      "           1      0.889     0.774     0.828        31\n",
      "           2      0.417     0.500     0.455        20\n",
      "           3      0.125     0.033     0.053        30\n",
      "           4      0.762     0.533     0.627        30\n",
      "           5      0.963     0.703     0.812        37\n",
      "\n",
      "    accuracy                          0.520       148\n",
      "   macro avg      0.526     0.424     0.462       148\n",
      "weighted avg      0.663     0.520     0.576       148\n",
      "\n",
      "memory 547.8203125\n",
      "time 0.8182821273803711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Flare dataset\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time, psutil\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "df=pd.read_csv('flare.txt', sep=\" \", header=None)\n",
    "\n",
    "df.drop_duplicates(keep='last',inplace=True)\n",
    "\n",
    "X=df.drop(0,axis=1)\n",
    "X=normalize(X)\n",
    "y=df[0]\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros,y_ros,test_size=0.2,random_state=42)\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "print('X_train :',X_train.shape)\n",
    "print('y_train :',y_train.shape)\n",
    "print('X_test :',X_test.shape)\n",
    "print('y_test :',y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "#WHOLE PROGRAM\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory\",process.memory_info().rss/ 1024 ** 2)\n",
    "t2=time.time()\n",
    "print(\"time\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMALvXf-DOvj",
    "outputId": "8ca85ea2-c917-4fbd-ce0a-7b80c77c6202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (377, 8)\n",
      "y_train : (377, 5)\n",
      "X_test : (95, 8)\n",
      "y_test : (95, 5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         0\n",
      "           1      0.857     0.750     0.800        16\n",
      "           2      0.737     0.583     0.651        24\n",
      "           3      0.762     0.727     0.744        22\n",
      "           4      0.957     0.667     0.786        33\n",
      "\n",
      "    accuracy                          0.674        95\n",
      "   macro avg      0.662     0.545     0.596        95\n",
      "weighted avg      0.839     0.674     0.745        95\n",
      "\n",
      "memory 549.09765625\n",
      "time 0.5571630001068115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Pima dataset\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time, psutil\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "df=pd.read_csv('pima.txt', sep=\" \", header=None)\n",
    "\n",
    "df.drop_duplicates(keep='last',inplace=True)\n",
    "\n",
    "X=df.drop(0,axis=1)\n",
    "X=normalize(X)\n",
    "y=df[0]\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros,y_ros,test_size=0.2,random_state=42)\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "print('X_train :',X_train.shape)\n",
    "print('y_train :',y_train.shape)\n",
    "print('X_test :',X_test.shape)\n",
    "print('y_test :',y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "#WHOLE PROGRAM\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory\",process.memory_info().rss/ 1024 ** 2)\n",
    "t2=time.time()\n",
    "print(\"time\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nHpgUnOBDVkQ",
    "outputId": "62309c33-a682-4368-95dd-193a9eb7a6d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (192, 19)\n",
      "y_train : (192, 6)\n",
      "X_test : (48, 19)\n",
      "y_test : (48, 6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      1.000     1.000     1.000        12\n",
      "           2      1.000     1.000     1.000        12\n",
      "           3      1.000     1.000     1.000        12\n",
      "           5      1.000     1.000     1.000        12\n",
      "\n",
      "    accuracy                          1.000        48\n",
      "   macro avg      1.000     1.000     1.000        48\n",
      "weighted avg      1.000     1.000     1.000        48\n",
      "\n",
      "memory 549.8046875\n",
      "time 0.43806934356689453\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Hepati dataset\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time, psutil\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "df=pd.read_csv('hepati.txt', sep=\" \", header=None)\n",
    "\n",
    "df.drop_duplicates(keep='last',inplace=True)\n",
    "df=df.dropna()\n",
    "\n",
    "X=df.drop(0,axis=1)\n",
    "X=normalize(X)\n",
    "y=df[0]\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros,y_ros,test_size=0.2,random_state=42)\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "print('X_train :',X_train.shape)\n",
    "print('y_train :',y_train.shape)\n",
    "print('X_test :',X_test.shape)\n",
    "print('y_test :',y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "#WHOLE PROGRAM\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory\",process.memory_info().rss/ 1024 ** 2)\n",
    "t2=time.time()\n",
    "print(\"time\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceFJ0V00DcQH",
    "outputId": "869404e5-0453-48b0-c11a-487aaaf06154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (192, 19)\n",
      "y_train : (192, 6)\n",
      "X_test : (48, 19)\n",
      "y_test : (48, 6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      1.000     1.000     1.000        12\n",
      "           2      1.000     1.000     1.000        12\n",
      "           3      1.000     1.000     1.000        12\n",
      "           5      1.000     1.000     1.000        12\n",
      "\n",
      "    accuracy                          1.000        48\n",
      "   macro avg      1.000     1.000     1.000        48\n",
      "weighted avg      1.000     1.000     1.000        48\n",
      "\n",
      "memory 550.8046875\n",
      "time 0.4664039611816406\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Anneal dataset\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time, psutil\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "prep = _Preprocess()\n",
    "with open('anneal.txt') as f:\n",
    "  raw_data = f.read().strip().split('\\n')\n",
    "X, y = prep.preprocess_data(raw_data)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros,y_ros,test_size=0.2,random_state=42)\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "print('X_train :',X_train.shape)\n",
    "print('y_train :',y_train.shape)\n",
    "print('X_test :',X_test.shape)\n",
    "print('y_test :',y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "#WHOLE PROGRAM\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory\",process.memory_info().rss/ 1024 ** 2)\n",
    "t2=time.time()\n",
    "print(\"time\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ysr5Z6aRDiCL",
    "outputId": "ebeabcee-d7a0-4cfe-9b61-7ca20398fa14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (371, 83)\n",
      "y_train : (371, 2)\n",
      "X_test : (93, 83)\n",
      "y_test : (93, 2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.946     0.972     0.959        36\n",
      "           1      0.982     0.965     0.973        57\n",
      "\n",
      "    accuracy                          0.968        93\n",
      "   macro avg      0.964     0.969     0.966        93\n",
      "weighted avg      0.968     0.968     0.968        93\n",
      "\n",
      "memory 551.31640625\n",
      "time 0.3583855628967285\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Horse dataset\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time, psutil\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "prep = _Preprocess()\n",
    "with open('horse.txt') as f:\n",
    "  raw_data = f.read().strip().split('\\n')\n",
    "X, y = prep.preprocess_data(raw_data)\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros,y_ros,test_size=0.2,random_state=42)\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "print('X_train :',X_train.shape)\n",
    "print('y_train :',y_train.shape)\n",
    "print('X_test :',X_test.shape)\n",
    "print('y_test :',y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "#WHOLE PROGRAM\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory\",process.memory_info().rss/ 1024 ** 2)\n",
    "t2=time.time()\n",
    "print(\"time\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5i4u8lpDnw2",
    "outputId": "15ad3c8e-25d3-4a56-98a6-8a6fac1d6bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (11635, 22)\n",
      "y_train : (11635, 7)\n",
      "X_test : (2909, 22)\n",
      "y_test : (2909, 7)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         0\n",
      "           1      0.914     0.956     0.934       455\n",
      "           2      0.892     1.000     0.943       480\n",
      "           3      0.157     0.149     0.153       483\n",
      "           4      0.228     0.207     0.217       517\n",
      "           5      0.952     0.907     0.929       505\n",
      "           6      0.969     1.000     0.984       469\n",
      "\n",
      "    accuracy                          0.695      2909\n",
      "   macro avg      0.587     0.603     0.594      2909\n",
      "weighted avg      0.678     0.695     0.686      2909\n",
      "\n",
      "memory 628.51171875\n",
      "time 12.442272901535034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Mushroom dataset\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time, psutil\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "df=pd.read_csv('mushroom.txt', sep=\" \", header=None)\n",
    "df=df.dropna()\n",
    "df.drop_duplicates(keep='last',inplace=True)\n",
    "\n",
    "X=df.drop(0,axis=1)\n",
    "X=normalize(X)\n",
    "y=df[0]\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros,y_ros,test_size=0.2,random_state=42)\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "print('X_train :',X_train.shape)\n",
    "print('y_train :',y_train.shape)\n",
    "print('X_test :',X_test.shape)\n",
    "print('y_test :',y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "#WHOLE PROGRAM\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory\",process.memory_info().rss/ 1024 ** 2)\n",
    "t2=time.time()\n",
    "print(\"time\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhD3ty_XDuI7",
    "outputId": "08af35cd-b5a0-4b95-d2ad-102d4d14bc10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (732, 18)\n",
      "y_train : (732, 2)\n",
      "X_test : (184, 18)\n",
      "y_test : (184, 2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.926     0.946        94\n",
      "           1      0.926     0.967     0.946        90\n",
      "\n",
      "    accuracy                          0.946       184\n",
      "   macro avg      0.946     0.946     0.946       184\n",
      "weighted avg      0.947     0.946     0.946       184\n",
      "\n",
      "memory 631.73046875\n",
      "time 0.38416028022766113\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Adult dataset\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time, psutil\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "class _Preprocess:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._label_encoder = None\n",
    "\n",
    "    def preprocess_data(self, raw_data):\n",
    "        \"\"\" Given one of UCI files specific to SigDirect paper data,\n",
    "            transform it to the common form used in sklearn datasets\"\"\"\n",
    "        transaction_data = [list(map(int, x.strip().split())) for x in raw_data]\n",
    "        max_val = max([max(x[:-1]) for x in transaction_data])\n",
    "        X, y = [], []\n",
    "\n",
    "        for transaction in transaction_data:\n",
    "            positions = np.array(transaction[:-1]) - 1\n",
    "            transaction_np = np.zeros((max_val))\n",
    "            transaction_np[positions] = 1\n",
    "            X.append(transaction_np)\n",
    "            y.append(transaction[-1])\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # converting labels\n",
    "        if self._label_encoder is None:  # train time\n",
    "            unique_classes = np.unique(y)\n",
    "            self._label_encoder = defaultdict(lambda: 0, zip(unique_classes, range(len(unique_classes))))\n",
    "            y = np.vectorize(self._label_encoder.get)(y)\n",
    "        else:  # test time\n",
    "            y = np.vectorize(lambda a: self._label_encoder[a])(y)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "prep = _Preprocess()\n",
    "with open('breast.txt') as f:\n",
    "  raw_data = f.read().strip().split('\\n')\n",
    "X, y = prep.preprocess_data(raw_data)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros,y_ros,test_size=0.2,random_state=42)\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "print('X_train :',X_train.shape)\n",
    "print('y_train :',y_train.shape)\n",
    "print('X_test :',X_test.shape)\n",
    "print('y_test :',y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "#WHOLE PROGRAM\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory\",process.memory_info().rss/ 1024 ** 2)\n",
    "t2=time.time()\n",
    "print(\"time\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbyiDzI1D2LQ",
    "outputId": "d0a827fc-8f04-44fd-b32a-6b1fca167d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (462, 34)\n",
      "y_train : (462, 3)\n",
      "X_test : (116, 34)\n",
      "y_test : (116, 3)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.930     1.000     0.964        53\n",
      "           2      1.000     0.937     0.967        63\n",
      "\n",
      "    accuracy                          0.966       116\n",
      "   macro avg      0.965     0.968     0.965       116\n",
      "weighted avg      0.968     0.966     0.966       116\n",
      "\n",
      "memory 628.69921875\n",
      "time 0.6405446529388428\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ionosphere dataset\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time, psutil\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "df=pd.read_csv('ionosphere.txt', sep=\" \", header=None)\n",
    "\n",
    "df.drop_duplicates(keep='last',inplace=True)\n",
    "\n",
    "X=df.drop(0,axis=1)\n",
    "X=normalize(X)\n",
    "y=df[0]\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros,y_ros,test_size=0.2,random_state=42)\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "print('X_train :',X_train.shape)\n",
    "print('y_train :',y_train.shape)\n",
    "print('X_test :',X_test.shape)\n",
    "print('y_test :',y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "#WHOLE PROGRAM\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"memory\",process.memory_info().rss/ 1024 ** 2)\n",
    "t2=time.time()\n",
    "print(\"time\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kf3TemXHD-OW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "RandomForest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
